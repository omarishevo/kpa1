import streamlit as st
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score

st.set_page_config(page_title="KPA Cargo Volume Flow Dashboard", layout="wide")

# --- Load Data ---
@st.cache_data
def load_data():
    df = pd.read_csv("kpa_personnel_dataset_final.csv")
    return df

df = load_data()
st.title("📊 KPA Cargo Volume Flow Forecast Dashboard")

# --- Preprocessing ---
shift_mapping = {'Day': 1, 'Night': 2, 'Rotational': 3}
df['Shift_encoded'] = df['Shift'].map(shift_mapping)

location_grouped = df.groupby('Work Location').agg({
    'Years of Experience': 'mean',
    'Shift_encoded': 'mean',
    'ID Number': 'count'
}).rename(columns={
    'Years of Experience': 'Avg_Experience',
    'Shift_encoded': 'Avg_Shift',
    'ID Number': 'Personnel_Count'
})

# Synthetic Cargo Volume Flow
np.random.seed(42)
location_grouped['Cargo_Volume_Flow'] = (
    location_grouped['Avg_Experience'] * 2 +
    location_grouped['Avg_Shift'] * 5 +
    location_grouped['Personnel_Count'] * 3 +
    np.random.normal(0, 5, size=location_grouped.shape[0])
)

# --- Model ---
X = location_grouped[['Avg_Experience', 'Avg_Shift', 'Personnel_Count']]
y = location_grouped['Cargo_Volume_Flow']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)
model = RandomForestRegressor(n_estimators=100, random_state=42)
model.fit(X_train, y_train)
y_pred = model.predict(X_test)
rmse = np.sqrt(mean_squared_error(y_test, y_pred))
r2 = r2_score(y_test, y_pred)

# --- Dashboard Sections ---
tab1, tab2, tab3 = st.tabs(["📈 Summary", "📊 Visualizations", "🔍 Feature Insights"])

with tab1:
    st.subheader("🔢 Model Summary Metrics")
    st.write(f"**Root Mean Squared Error (RMSE):** {rmse:.2f}")
    st.write(f"**R² Score:** {r2:.2f}")

    st.subheader("🧾 Aggregated Data by Work Location")
    st.dataframe(location_grouped.reset_index())

with tab2:
    st.subheader("📍 Cargo Volume Flow by Work Location")
    fig1, ax1 = plt.subplots(figsize=(10, 5))
    location_grouped.sort_values("Cargo_Volume_Flow", ascending=False)['Cargo_Volume_Flow'].plot(kind='bar', ax=ax1)
    ax1.set_ylabel("Cargo Volume Flow")
    ax1.set_title("Cargo Volume Flow per Work Location")
    st.pyplot(fig1)

    st.subheader("📌 Correlation Heatmap")
    fig2, ax2 = plt.subplots()
    sns.heatmap(location_grouped.corr(), annot=True, cmap="coolwarm", ax=ax2)
    st.pyplot(fig2)

with tab3:
    st.subheader("🔧 Feature Importance")
    importances = model.feature_importances_
    features = X.columns
    fig3, ax3 = plt.subplots()
    sns.barplot(x=importances, y=features, palette="viridis", ax=ax3)
    ax3.set_title("Feature Importance in Predicting Cargo Volume Flow")
    st.pyplot(fig3)

    st.subheader("🔁 Actual vs Predicted Cargo Flow")
    fig4, ax4 = plt.subplots()
    ax4.plot(y_test.values, label="Actual", marker='o')
    ax4.plot(y_pred, label="Predicted", marker='x')
    ax4.set_title("Actual vs Predicted Cargo Volume Flow")
    ax4.set_ylabel("Cargo Volume")
    ax4.legend()
    st.pyplot(fig4)


